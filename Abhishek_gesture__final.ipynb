{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvwE2LzYpqlB"
      },
      "source": [
        "# Gesture Recognition\n",
        "In this project, I have build a 3D Conv model that will be able to predict the 5 gestures correctly.If you want to understand the project , I have given the instructions to follow .  import the following libraries to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiKs_Ez0myoK",
        "outputId": "b46585ae-d673-4fed-9f43-c2f7c7391dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.21.6)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "jax 0.3.4 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.1.0\n"
          ]
        }
      ],
      "source": [
        "#installing scipy old version to read,resize image data\n",
        "pip install scipy==1.1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnRlpGHfpqlK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "#from scipy.misc.pilutil import imread, imresize\n",
        "import datetime\n",
        "import os\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrEkk9oQpqlL"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-i-7ymMpqlM"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBTpr4VSrgtd",
        "outputId": "8c34180c-93aa-4b09-9963-e50391b23d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS_XmtH2pqlN"
      },
      "source": [
        "In this block, I read the folder names for training and validation. I also set the `batch_size` here. Note that I set the batch size in such a way that I amable to use the GPU in full capacity. I keep increasing the batch size until the machine throws an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVn9mEA8pqlO"
      },
      "outputs": [],
      "source": [
        "# train and validatiaon data creator with ablation\n",
        "# when ablation is 10, then 10 folders for each label will be selected.\n",
        "def get_data(path, ablation=None):\n",
        "    train_doc = np.random.permutation(open(path+'train.csv').readlines())\n",
        "    val_doc = np.random.permutation(open(path+'val.csv').readlines())\n",
        "    counts = np.zeros(5) # count for loading folders for 5 classes\n",
        "    train_data = []\n",
        "    val_data = []\n",
        "    # when ablation is None pass full training and val data\n",
        "    if ablation is not None:\n",
        "        # iterating train doc\n",
        "        for doc in train_doc:\n",
        "            lable = int(doc.strip().split(';')[2])\n",
        "            if counts[lable] < ablation:\n",
        "                train_data.append(doc)\n",
        "                counts[lable] += 1 \n",
        "        counts = np.zeros(5)\n",
        "        # iterating val doc\n",
        "        for doc in val_doc:\n",
        "            lable = int(doc.strip().split(';')[2])\n",
        "            if counts[lable] < ablation:\n",
        "                val_data.append(doc)\n",
        "                counts[lable] += 1\n",
        "    else:\n",
        "        train_data, val_data = train_doc, val_doc\n",
        "    return train_data, val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rwOTxJvpqlP"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
        "batch_size = 32\n",
        "\n",
        "# experiment with the batch size\n",
        "enable_augmentation = False # augmentation of Data\n",
        "# sequence ids\n",
        "# selecting alternate frames from 7 to 26.\n",
        "seq_idx = range(7,26,2)\n",
        "# image dimensions\n",
        "dim_x, dim_y = 120, 120"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvr54DlnpqlQ"
      },
      "source": [
        "## Generator\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, I am going to preprocess the images as I have images of 2 different dimensions as well as create a batch of video frames. I have to experiment with `img_idx`, `y`,`z` and normalization such that I get high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyLhUajypqlR",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# generator with augmentation for train data\n",
        "def generator(source_path, folder_list, batch_size, is_train = False, augmention = False, debug=False):\n",
        "    # print('\\nSource path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = seq_idx #create a list of image numbers I want to use for a particular video\n",
        "    x = len(img_idx)\n",
        "    y, z = dim_x, dim_y\n",
        "    while True:\n",
        "        # doubling the data for augmentation\n",
        "        if is_train and augmention:\n",
        "            t = np.concatenate((np.random.permutation(folder_list), np.random.permutation(folder_list)))\n",
        "        else:\n",
        "            t = np.random.permutation(folder_list)\n",
        "            \n",
        "        if (len(t)%batch_size) == 0:\n",
        "            num_batches = int(len(t)/batch_size)\n",
        "        else:\n",
        "            num_batches = len(t)//batch_size + 1\n",
        "            \n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images I use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                if debug:\n",
        "                    plt.figure(figsize=(20,5))\n",
        "                #handling remaining datapoints\n",
        "                folder_idx = folder + (batch*batch_size)\n",
        "                if folder_idx >= len(t):\n",
        "                    break\n",
        "                folder_str = t[folder_idx]\n",
        "                imgs = os.listdir(source_path+'/'+ folder_str.split(';')[0]) # read all the images in the folder\n",
        "                # randomly enabling augmentation and augmentation type\n",
        "                aug_type = None\n",
        "                if is_train and augmention and rn.randint(0,1) == 1:\n",
        "                    aug_type = rn.randint(0, 4) #randomly selecting augmentation type\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ folder_str.strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    # plotting original images for debugging purpose only\n",
        "                    if debug:\n",
        "                        plt.subplot(2, x, idx+1)\n",
        "                        plt.imshow(image.astype('uint8'))\n",
        "\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    # making the rectangle images into square by cropping sides\n",
        "                    # so the aspect ration can be mantained while resizing.\n",
        "                    if image.shape[1] > image.shape[0]:\n",
        "                        diff_px = image.shape[1] - image.shape[0]\n",
        "                        crop_start = diff_px//2\n",
        "                        crop_end = crop_start + image.shape[0]\n",
        "                        image = image[:, crop_start:crop_end]\n",
        "                    elif image.shape[0] > image.shape[1]:\n",
        "                        diff_px = image.shape[0] - image.shape[1]\n",
        "                        crop_start = diff_px//2\n",
        "                        crop_end = crop_start + image.shape[1]\n",
        "                        image = image[:, crop_start:crop_end]\n",
        "\n",
        "                    resized_im = imresize(image, size=(y,z))\n",
        "\n",
        "                    if aug_type is not None:\n",
        "                        if aug_type == 0: # edge Enhancement\n",
        "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.EDGE_ENHANCE))\n",
        "                        elif aug_type == 1: # c\n",
        "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.GaussianBlur(1)))\n",
        "                        elif aug_type == 2: # c\n",
        "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.DETAIL))\n",
        "                        elif aug_type == 3: # sharpening image\n",
        "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.SHARPEN))\n",
        "                        elif aug_type == 4: # Brightness enhancement\n",
        "                            resized_im = np.array(ImageEnhance.Brightness((Image.fromarray(resized_im, 'RGB'))).enhance(1.5))\n",
        "                    # plotting rezised images for debugging purpose only\n",
        "                    if debug:\n",
        "                        plt.subplot(2, x, idx+x+1)\n",
        "                        plt.imshow(resized_im)\n",
        "\n",
        "                    batch_data[folder,idx,:,:,0] = resized_im[:,:,0]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = resized_im[:,:,1]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = resized_im[:,:,2]/255 #normalise and feed in the image\n",
        "\n",
        "                batch_labels[folder, int(folder_str.strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels #I yield the batch_data and the batch_labels, remember what does yield do\n",
        "                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGpPcmaWpqlV"
      },
      "source": [
        "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBlc6ybyf5lB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whSGP0PRpqlV",
        "outputId": "b2b9805a-8b4f-4514-8121-5494451e71f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 50\n"
          ]
        }
      ],
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = 'Project_data/train' #'/notebooks/storage/Final_data/Collated_training/train'\n",
        "val_path =  'Project_data/csv' #'/notebooks/storage/Final_data/Collated_training/val'\n",
        "\n",
        "#multiply number train seq by 2 when using augmentation\n",
        "multiplier = 1\n",
        "if enable_augmentation:\n",
        "    multiplier = 2\n",
        "num_train_sequences = len(train_doc)*multiplier\n",
        "print('# training sequences =', num_train_sequences)\n",
        "\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "\n",
        "num_epochs = 50 # choose the number of epochs\n",
        "print ('# epochs =', num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eaj0mYpXpqlW"
      },
      "outputs": [],
      "source": [
        "# testing generative \n",
        "test_gen = generator(train_path, train_doc, 1, is_train = True, augmention = True, debug = True)\n",
        "d = next(test_gen)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFVc9psJpqlW"
      },
      "source": [
        "## Model\n",
        "Here I make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. I would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK0uTxthpqlX"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Bidirectional, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, GlobalAveragePooling3D, ConvLSTM2D\n",
        "from keras.layers.convolutional import Conv2D, Conv3D, MaxPooling2D, MaxPooling3D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "\n",
        "#input shape for the st layer\n",
        "input_shape = (len(seq_idx), dim_x, dim_y, 3)\n",
        "np.random.seed(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJUygEOmpqlX"
      },
      "source": [
        "### Experiment - 1 & 2\n",
        "**Conv3D**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4WYY37TpqlY"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        " model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        " model.add(MaxPooling3D(pool_size=2))\n",
        "\n",
        " model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=2))\n",
        "\n",
        " model.add(Flatten())\n",
        " model.add(Dense(256, activation='relu'))\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RQzGTg2wU8A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AEo259Rwj0_"
      },
      "outputs": [],
      "source": [
        "#Now that I have written the model, the next step is to compile the model. When I print the summary of the model, I'll see the total number of parameters I have to train.\n",
        "optimiser = tf.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "# The train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC6WqHvCwUrI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngWhxN6Iwt5E"
      },
      "outputs": [],
      "source": [
        "# fitting  the model. This will start training the model and with the help of the checkpoints, I will save the model at the end of each epoch.\n",
        "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDqsWWQHwlg2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW2wYMxIt9sD"
      },
      "outputs": [],
      "source": [
        "#Experiment 3\n",
        "\n",
        "#conv3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j38LScOOpqlZ"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        "\n",
        " model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        " model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        " model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "\n",
        " model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu')) \n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "\n",
        " model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu')) \n",
        " model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "\n",
        " model.add(Flatten())\n",
        " model.add(Dense(512, activation='relu'))\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYJ-Lb1NDsOH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nawu-BnmDv1N",
        "outputId": "238e1160-fc11-4e04-8e9b-02e9255ddc6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_2 (Conv3D)           (None, 8, 118, 118, 32)   2624      \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 6, 116, 116, 64)   55360     \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 3, 58, 58, 64)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 1, 56, 56, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPooling  (None, 1, 28, 28, 128)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 1, 26, 26, 256)    295168    \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPooling  (None, 1, 13, 13, 256)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_6 (Conv3D)           (None, 1, 11, 11, 512)    1180160   \n",
            "                                                                 \n",
            " conv3d_7 (Conv3D)           (None, 1, 9, 9, 512)      2359808   \n",
            "                                                                 \n",
            " max_pooling3d_5 (MaxPooling  (None, 1, 4, 4, 512)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               4194816   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,311,813\n",
            "Trainable params: 8,311,813\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#Now that I have written the model, the next step is to compile the model. \n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "# creating the train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygrnI9KPDz1y"
      },
      "outputs": [],
      "source": [
        "# fitting the model. This will start training the model and with the help of the checkpoints\n",
        "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GsgkId9Dr-n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNzfQKzrpqla"
      },
      "source": [
        "### Experiment - 4 \n",
        "**Conv3D**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72gKsiA3pqlb"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        "\n",
        " model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        " model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        " model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(Flatten())\n",
        " model.add(Dense(512, activation='relu'))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCY3Cv9mD_hZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqzM9t4tEDIn",
        "outputId": "57f7484b-7d88-426c-a771-6ff8e96e863b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_8 (Conv3D)           (None, 8, 118, 118, 32)   2624      \n",
            "                                                                 \n",
            " conv3d_9 (Conv3D)           (None, 6, 116, 116, 64)   55360     \n",
            "                                                                 \n",
            " max_pooling3d_6 (MaxPooling  (None, 3, 58, 58, 64)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 3, 58, 58, 64)    256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv3d_10 (Conv3D)          (None, 1, 56, 56, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_7 (MaxPooling  (None, 1, 28, 28, 128)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1, 28, 28, 128)   512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_11 (Conv3D)          (None, 1, 26, 26, 256)    295168    \n",
            "                                                                 \n",
            " max_pooling3d_8 (MaxPooling  (None, 1, 13, 13, 256)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1, 13, 13, 256)   1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_12 (Conv3D)          (None, 1, 11, 11, 512)    1180160   \n",
            "                                                                 \n",
            " conv3d_13 (Conv3D)          (None, 1, 9, 9, 512)      2359808   \n",
            "                                                                 \n",
            " max_pooling3d_9 (MaxPooling  (None, 1, 4, 4, 512)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 1, 4, 4, 512)     2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               4194816   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,317,701\n",
            "Trainable params: 8,314,757\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#Now that I have write the model, the next step is to compile the model. When I print the summary of the model, I'll see the total number of parameters I have to train.\n",
        "optimiser = tf.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "# creating the train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8crP59IeEGKL"
      },
      "outputs": [],
      "source": [
        "# fitting the model. This will start training the model and with the help of the \n",
        "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr04Htsau1QX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgmUP5Qju11N"
      },
      "source": [
        "### Experiment - 5(with dropout =0.5\n",
        "**Conv3D**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAEuwKyGup8p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYvUrXc-urcs"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(18,120,120,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(128, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(128, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiqtKphlup21"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAVhwVB-vhlL",
        "outputId": "d5ce6b2e-50d3-4577-9576-d15daf768ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#creating train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfTKMIhrvmSa",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "optimiser = tf.optimizers.Adam(lr=0.01) #write Ir optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtAnxLFpups2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlEUerimvyjL",
        "outputId": "3d1a96eb-77a3-41b6-ccd1-b336a11fbcd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_14 (Conv3D)          (None, 18, 120, 120, 32)  2624      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 18, 120, 120, 32)  0         \n",
            "                                                                 \n",
            " conv3d_15 (Conv3D)          (None, 18, 120, 120, 32)  27680     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 18, 120, 120, 32)  0         \n",
            "                                                                 \n",
            " max_pooling3d_10 (MaxPoolin  (None, 6, 40, 40, 32)    0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 6, 40, 40, 32)    128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_16 (Conv3D)          (None, 6, 40, 40, 64)     55360     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6, 40, 40, 64)     0         \n",
            "                                                                 \n",
            " conv3d_17 (Conv3D)          (None, 6, 40, 40, 64)     110656    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 6, 40, 40, 64)     0         \n",
            "                                                                 \n",
            " max_pooling3d_11 (MaxPoolin  (None, 2, 14, 14, 64)    0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 2, 14, 14, 64)    256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_18 (Conv3D)          (None, 2, 14, 14, 128)    221312    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 2, 14, 14, 128)    0         \n",
            "                                                                 \n",
            " conv3d_19 (Conv3D)          (None, 2, 14, 14, 128)    442496    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 2, 14, 14, 128)    0         \n",
            "                                                                 \n",
            " max_pooling3d_12 (MaxPoolin  (None, 1, 5, 5, 128)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 1, 5, 5, 128)     512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               1638912   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,533,093\n",
            "Trainable params: 2,532,645\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbY5GBTivsMe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRjKXJz1v6Zn",
        "outputId": "21b67b11-c7f2-4203-a3c5-a893b1cf11d4",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 3.1126 - categorical_accuracy: 0.2262  \n",
            "Epoch 1: saving model to model_init_2022-04-2007_35_23.002461/model-00001-3.11263-0.22619-1.26001-0.35938.h5\n",
            "21/21 [==============================] - 3135s 154s/step - loss: 3.1126 - categorical_accuracy: 0.2262 - val_loss: 1.2600 - val_categorical_accuracy: 0.3594 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5880 - categorical_accuracy: 0.2262 \n",
            "Epoch 2: saving model to model_init_2022-04-2007_35_23.002461/model-00002-1.58797-0.22619-1.25697-0.34375.h5\n",
            "21/21 [==============================] - 1244s 59s/step - loss: 1.5880 - categorical_accuracy: 0.2262 - val_loss: 1.2570 - val_categorical_accuracy: 0.3438 - lr: 0.0100\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5858 - categorical_accuracy: 0.2158 \n",
            "Epoch 3: saving model to model_init_2022-04-2007_35_23.002461/model-00003-1.58583-0.21577-1.25606-0.35156.h5\n",
            "21/21 [==============================] - 1244s 59s/step - loss: 1.5858 - categorical_accuracy: 0.2158 - val_loss: 1.2561 - val_categorical_accuracy: 0.3516 - lr: 0.0100\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5849 - categorical_accuracy: 0.2173 \n",
            "Epoch 4: saving model to model_init_2022-04-2007_35_23.002461/model-00004-1.58486-0.21726-1.25717-0.35938.h5\n",
            "21/21 [==============================] - 1242s 59s/step - loss: 1.5849 - categorical_accuracy: 0.2173 - val_loss: 1.2572 - val_categorical_accuracy: 0.3594 - lr: 0.0100\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5832 - categorical_accuracy: 0.1949 \n",
            "Epoch 5: saving model to model_init_2022-04-2007_35_23.002461/model-00005-1.58322-0.19494-1.25554-0.16406.h5\n",
            "21/21 [==============================] - 1242s 59s/step - loss: 1.5832 - categorical_accuracy: 0.1949 - val_loss: 1.2555 - val_categorical_accuracy: 0.1641 - lr: 0.0100\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5832 - categorical_accuracy: 0.1994 \n",
            "Epoch 6: saving model to model_init_2022-04-2007_35_23.002461/model-00006-1.58319-0.19940-1.25269-0.19531.h5\n",
            "21/21 [==============================] - 1245s 59s/step - loss: 1.5832 - categorical_accuracy: 0.1994 - val_loss: 1.2527 - val_categorical_accuracy: 0.1953 - lr: 0.0100\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5850 - categorical_accuracy: 0.1979 \n",
            "Epoch 7: saving model to model_init_2022-04-2007_35_23.002461/model-00007-1.58503-0.19792-1.25574-0.20312.h5\n",
            "21/21 [==============================] - 1243s 59s/step - loss: 1.5850 - categorical_accuracy: 0.1979 - val_loss: 1.2557 - val_categorical_accuracy: 0.2031 - lr: 0.0100\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5854 - categorical_accuracy: 0.2024 \n",
            "Epoch 8: saving model to model_init_2022-04-2007_35_23.002461/model-00008-1.58544-0.20238-1.25548-0.16406.h5\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "21/21 [==============================] - 1243s 59s/step - loss: 1.5854 - categorical_accuracy: 0.2024 - val_loss: 1.2555 - val_categorical_accuracy: 0.1641 - lr: 0.0100\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5837 - categorical_accuracy: 0.2083 "
          ]
        }
      ],
      "source": [
        "history = model2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                        callbacks=callbacks_list, validation_data=val_generator, \n",
        "                        validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnbKv1idvsHY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiMD812MvsEE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6UPohohpqlb"
      },
      "source": [
        "### Experiment - 6\n",
        "**Conv3D**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RQwHKPNPxxx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1N7VAoHPyiT"
      },
      "outputs": [],
      "source": [
        "Experiment  -7\n",
        "conv3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqeSWxvSJxl3"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(18,120,120,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(128, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(128, kernel_size=(3, 3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qekQ_s0tVLr",
        "outputId": "71899172-518f-4bcf-c698-b1c187a99962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_20 (Conv3D)          (None, 18, 120, 120, 32)  2624      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 18, 120, 120, 32)  0         \n",
            "                                                                 \n",
            " conv3d_21 (Conv3D)          (None, 18, 120, 120, 32)  27680     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 18, 120, 120, 32)  0         \n",
            "                                                                 \n",
            " max_pooling3d_13 (MaxPoolin  (None, 6, 40, 40, 32)    0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 6, 40, 40, 32)    128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_22 (Conv3D)          (None, 6, 40, 40, 64)     55360     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 6, 40, 40, 64)     0         \n",
            "                                                                 \n",
            " conv3d_23 (Conv3D)          (None, 6, 40, 40, 64)     110656    \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 6, 40, 40, 64)     0         \n",
            "                                                                 \n",
            " max_pooling3d_14 (MaxPoolin  (None, 2, 14, 14, 64)    0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 2, 14, 14, 64)    256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_24 (Conv3D)          (None, 2, 14, 14, 128)    221312    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 2, 14, 14, 128)    0         \n",
            "                                                                 \n",
            " conv3d_25 (Conv3D)          (None, 2, 14, 14, 128)    442496    \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 2, 14, 14, 128)    0         \n",
            "                                                                 \n",
            " max_pooling3d_15 (MaxPoolin  (None, 1, 5, 5, 128)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 1, 5, 5, 128)     512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 512)               1638912   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,533,093\n",
            "Trainable params: 2,532,645\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#Now that I have written the model, the next step is to compile the model. When I print the summary of the model, I'll see the total number of parameters I have to train.\n",
        "optimiser = tf.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "#creating the train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk4zubsEtYVv"
      },
      "outputs": [],
      "source": [
        "#fitting will start training the model and with the help of the checkpoints, I'll be able to save the model at the end of each epoch.\n",
        "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rEyYN_5pqlc"
      },
      "source": [
        "### Experiment - 8\n",
        "**Conv3D**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbtPgdSHpqlc"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        "\n",
        " model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        " model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
        " model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(Flatten())\n",
        " model.add(Dense(512, activation='relu'))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9hb1RD6Eil6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C72AtXEbEjIr",
        "outputId": "8a456524-ea85-459d-fba1-a6799b4d8c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_26 (Conv3D)          (None, 8, 118, 118, 32)   2624      \n",
            "                                                                 \n",
            " conv3d_27 (Conv3D)          (None, 6, 116, 116, 64)   55360     \n",
            "                                                                 \n",
            " max_pooling3d_16 (MaxPoolin  (None, 3, 58, 58, 64)    0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 3, 58, 58, 64)    256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3, 58, 58, 64)     0         \n",
            "                                                                 \n",
            " conv3d_28 (Conv3D)          (None, 1, 56, 56, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_17 (MaxPoolin  (None, 1, 28, 28, 128)   0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 1, 28, 28, 128)   512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 28, 28, 128)    0         \n",
            "                                                                 \n",
            " conv3d_29 (Conv3D)          (None, 1, 26, 26, 256)    295168    \n",
            "                                                                 \n",
            " max_pooling3d_18 (MaxPoolin  (None, 1, 13, 13, 256)   0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 1, 13, 13, 256)   1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1, 13, 13, 256)    0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 43264)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               22151680  \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,732,549\n",
            "Trainable params: 22,730,629\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#Now that I have written the model, the next step is to compile the model. When I print the summary of the model, I'll see the total number of parameters I have to train.\n",
        "optimiser = tf.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "#creating the train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUNN3wfLEm02"
      },
      "outputs": [],
      "source": [
        "#fitting the model. This will start training the model and with the help of the checkpoints, I'll be able to save the model at the end of each epoch.\n",
        "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks1VzjxVE_ji"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkunKQJppqle"
      },
      "source": [
        "### Experiment - 9.a(without dropout)\n",
        "**TimeDistributed Conv2D + GRU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K7DzZztpqle"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        " model.add(TimeDistributed(\n",
        "     Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
        " )\n",
        " model.add(TimeDistributed(\n",
        "     MaxPooling2D((2,2)))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(TimeDistributed(\n",
        "     Conv2D(64, (3,3), activation='relu'))\n",
        " )\n",
        " model.add(TimeDistributed(\n",
        "     MaxPooling2D((2,2)))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        " model.add(TimeDistributed(Dense(64, activation='relu')))\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(GRU(128))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5glUGLZFwnZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_OYjZGIFxGL",
        "outputId": "25df9ddb-4df8-47d6-90e8-3365e159ef9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_24 (TimeDi  (None, 10, 118, 118, 32)  896      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_25 (TimeDi  (None, 10, 59, 59, 32)   0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 10, 59, 59, 32)   128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_26 (TimeDi  (None, 10, 57, 57, 64)   18496     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_27 (TimeDi  (None, 10, 28, 28, 64)   0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 10, 28, 28, 64)   256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_28 (TimeDi  (None, 10, 64)           0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_29 (TimeDi  (None, 10, 64)           4160      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 10, 64)           256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 128)               74496     \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99,845\n",
            "Trainable params: 99,269\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#Now that I have written the model, the next step is to compile the model. When I print the summary of the model, I'll see the total number of parameters I have to train.\n",
        "optimiser = tf.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "#creating the train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApYkfm4EF0IJ"
      },
      "outputs": [],
      "source": [
        "#fitting the model. This will start training the model and with the help of the checkpoints, I'll be able to save the model at the end of each epoch.\n",
        "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULWhgZRspqle"
      },
      "source": [
        "### Experiment - 9.b(with dropout =0.2)\n",
        "**TimeDistributed Conv2D + GRU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOD1F4VQpqle"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        " model.add(TimeDistributed(\n",
        "    Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
        " )\n",
        " model.add(TimeDistributed(\n",
        "     MaxPooling2D((2,2)))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(TimeDistributed(\n",
        "     Conv2D(64, (3,3), activation='relu'))\n",
        " )\n",
        " model.add(TimeDistributed(\n",
        "     MaxPooling2D((2,2)))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        " model.add(TimeDistributed(Dense(64, activation='relu')))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dropout(0.2))\n",
        "\n",
        " model.add(GRU(128))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR1T2xG9Z5fH",
        "outputId": "27061425-3862-468e-863d-3641f62e3be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_6 (TimeDis  (None, 10, 118, 118, 32)  896      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 10, 59, 59, 32)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 10, 59, 59, 32)   128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 10, 59, 59, 32)    0         \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDis  (None, 10, 57, 57, 64)   18496     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, 10, 28, 28, 64)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 10, 28, 28, 64)   256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 10, 28, 28, 64)    0         \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, 10, 64)           0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, 10, 64)           4160      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 10, 64)           256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 10, 64)            0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 128)               74496     \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99,845\n",
            "Trainable params: 99,269\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#Now that I have written the model, the next step is to compile the model. When I print the summary of the model, I'll see the total number of parameters I have to train.\n",
        "optimiser = tf.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "#creating the train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kBH5gzfaC0Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYhYUhx5aDSS",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                        callbacks=callbacks_list, validation_data=val_generator, \n",
        "                        validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWLicwP7pqlf"
      },
      "source": [
        "### Experiment - 10\n",
        "**TimeDistributed Conv2D + Dense**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBpEeadSpqlf"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        " model.add(TimeDistributed(\n",
        "     Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
        " )\n",
        " model.add(TimeDistributed(\n",
        "     MaxPooling2D((2,2)))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(TimeDistributed(\n",
        "     Conv2D(64, (3,3), activation='relu'))\n",
        " )\n",
        " model.add(TimeDistributed(\n",
        "     MaxPooling2D((2,2)))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(TimeDistributed(\n",
        "     Conv2D(128, (3,3), activation='relu'))\n",
        " )\n",
        " model.add(TimeDistributed(\n",
        "     MaxPooling2D((2,2)))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        "\n",
        " model.add(GlobalAveragePooling3D())\n",
        " model.add(Dense(256, activation='relu'))\n",
        " model.add(BatchNormalization())\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFADTEWAyCEc",
        "outputId": "ac0797f3-7633-4433-a862-63e016b19767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_12 (TimeDi  (None, 10, 118, 118, 32)  896      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_13 (TimeDi  (None, 10, 59, 59, 32)   0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 10, 59, 59, 32)   128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 10, 57, 57, 64)   18496     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_15 (TimeDi  (None, 10, 28, 28, 64)   0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 10, 28, 28, 64)   256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_16 (TimeDi  (None, 10, 26, 26, 128)  73856     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_17 (TimeDi  (None, 10, 13, 13, 128)  0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 10, 13, 13, 128)  512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling3d (G  (None, 128)              0         \n",
            " lobalAveragePooling3D)                                          \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 129,477\n",
            "Trainable params: 128,517\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#Now that I have written the model, the next step is to compile the model. When I print the summary of the model, I'll see the total number of parameters I have to train.\n",
        "optimiser = tf.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "#creating the train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJAOAniNyEBr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyVRdmATpqlf"
      },
      "source": [
        "### Experiment - 11\n",
        "**TimeDistributed + ConvLSTM2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFK1okzWpqlg"
      },
      "outputs": [],
      "source": [
        " model = Sequential()\n",
        " model.add(TimeDistributed(\n",
        "    Conv2D(8, (3,3), activation='relu'), input_shape=input_shape)\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        " model.add(TimeDistributed(\n",
        "     Conv2D(16, (3,3), activation='relu'))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        " model.add(\n",
        "     ConvLSTM2D(8, kernel_size = 3, return_sequences=False)\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        " model.add(TimeDistributed(\n",
        "     Dense(64, activation='relu'))\n",
        " )\n",
        " model.add(BatchNormalization())\n",
        " model.add(GlobalAveragePooling2D())\n",
        " model.add(Dense(64, activation='relu'))\n",
        " model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhub-VcfQ4m_",
        "outputId": "18790062-3ded-4681-bd06-3b4913de89be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_18 (TimeDi  (None, 10, 118, 118, 8)  224       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 10, 118, 118, 8)  32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_19 (TimeDi  (None, 10, 116, 116, 16)  1168     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 10, 116, 116, 16)  64       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv_lstm2d (ConvLSTM2D)    (None, 114, 114, 8)       6944      \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 114, 114, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_20 (TimeDi  (None, 114, 114, 64)     576       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 114, 114, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,781\n",
            "Trainable params: 13,589\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "#Now that I have written the model, the next step is to compile the model. When I print the summary of the model, I'll see the total number of parameters I have to train.\n",
        "optimiser = tf.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'],run_eagerly=True)\n",
        "print (model.summary())\n",
        "\n",
        "#creating the train_generator and the val_generator which will be used in .fit_generator\n",
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR =  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n",
        "#The steps_per_epoch and validation_steps are used by fit_generator to decide the number of next() calls it need to make.if (num_train_sequences%batch_size) == 0:\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPpxB794Q7OP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vEmFEORyImX",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                        callbacks=callbacks_list, validation_data=val_generator, \n",
        "                        validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdL0eCohpqlg"
      },
      "source": [
        "# Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUxJ8I95pqlh"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(8, (3,3), activation='relu'), input_shape=input_shape)\n",
        ")\n",
        "model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(16, (3,3), activation='relu'))\n",
        ")\n",
        "model.add(BatchNormalization())\n",
        "model.add(\n",
        "    ConvLSTM2D(8, kernel_size = 3, return_sequences=False)\n",
        ")\n",
        "model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(\n",
        "    Dense(64, activation='relu'))\n",
        ")\n",
        "model.add(BatchNormalization())\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLrwcn7qpqli"
      },
      "source": [
        "Now that I have written the model, the next step is to `compile` the model. When I print the `summary` of the model, I'll see the total number of parameters I have to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orZizTCFpqlj",
        "outputId": "fb571373-e82e-4c8c-e40e-5b939827038b",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_21 (TimeDi  (None, 10, 118, 118, 8)  224       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 10, 118, 118, 8)  32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_22 (TimeDi  (None, 10, 116, 116, 16)  1168     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 10, 116, 116, 16)  64       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv_lstm2d_1 (ConvLSTM2D)  (None, 114, 114, 8)       6944      \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 114, 114, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_23 (TimeDi  (None, 114, 114, 64)     576       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 114, 114, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,781\n",
            "Trainable params: 13,589\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "optimiser = tf.optimizers.Adam(lr=0.01) #write Ir optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsTCQJFepqlk"
      },
      "source": [
        "creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Go8gOD1pqlk"
      },
      "outputs": [],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, is_train = True, augmention = enable_augmentation)\n",
        "val_generator = generator(val_path, val_doc, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES7oxbyQpqll",
        "outputId": "58db2c3d-c427-4ef7-c9ad-d63d930ccd0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "model_name = 'model_init_exp_16' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, verbose=1) # write the REducelronplateau code here\n",
        "\n",
        "callbacks_list = [checkpoint, LR]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bky7Tj7ypqll"
      },
      "source": [
        "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW35stxqpqll"
      },
      "outputs": [],
      "source": [
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZNhRCZ3pqll"
      },
      "source": [
        "fitting the model. This will start training the model and with the help of the checkpoints, I'll be able to save the model at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i2tChtopqlm",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                        callbacks=callbacks_list, validation_data=val_generator, \n",
        "                        validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA5HL4y4pqlm"
      },
      "outputs": [],
      "source": [
        " "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}